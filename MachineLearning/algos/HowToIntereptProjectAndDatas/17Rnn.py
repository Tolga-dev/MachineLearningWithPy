# representation and generative learning using autoencoders and gans

# autoencoders are ann-capable of learning dense representations of input data called
# latent representations, or codings without any supervision

# it acts like a feature detector
# they can generate also a data that is super similar to training data,
# for example, we could train an autoencoder on pictures of faces, but pics can be fuzzy and not realistic

# in contrast, faces generated by generative adversarial network (GAN) are improved a lot

# autoencoders and gan are both unsupervised, they both learn dense representations
# they can be both used as generative models, and they have many similar apps, however

# autoencoders
# simply learn to copy their inputs to their outputs, trivial task

# GAN
# a generator that tries to generate data that looks similar to the training data.
# and a discriminator, to tell real data from fake data.
# similar to deep learning in that, the generator and the discriminator compete against each other during training.

# how autoencoders works and how to use them for dimensionality reduction, feature extraction,
# unsupervised pretraining or as generative models.

# efficient data representation

# stacked autoencoders
# they can have multiple hidden layers, adding more layers helps the autoencoder learn more complex encodings.
#

import joblib
import keras
import numpy as np
from matplotlib import pyplot as plt
from sklearn.manifold import TSNE
import matplotlib as mpl
import tensorflow as tf

train_model_cache_download = joblib.Memory('./tmp/represent/train_model_cache_download')


@train_model_cache_download.cache
def getDataImdbFrom():
    pass


def plot_image(image):
    plt.imshow(image, cmap="binary")
    plt.axis("off")
    plt.show()

def rounded_accuracy(y_true, y_pred):
    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))

class TrainingExercises:
    def __init__(self):
        print("k")
        # similar to regular deep mlp
        # using SELU activation function
        (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()
        X_train_full = X_train_full.astype(np.float32) / 255
        X_test = X_test.astype(np.float32) / 255
        X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]
        y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]

        # stacked_encoder = keras.models.Sequential(
        #     [
        #         keras.layers.Flatten(input_shape=[28, 28]),
        #         keras.layers.Dense(100, activation="selu"),
        #         keras.layers.Dense(30, activation="selu"),
        #     ]
        # )
        # stacked_decoder = keras.models.Sequential([
        #     keras.layers.Dense(100, activation="selu", input_shape=[30]),
        #     keras.layers.Dense(28 * 28, activation="sigmoid"),
        #     keras.layers.Reshape([28, 28])
        # ])
        # stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])
        # stacked_ae.compile(loss="binary_crossentropy",
        #                    optimizer=keras.optimizers.SGD(lr=1.5))
        # history = stacked_ae.fit(X_train, X_train, epochs=10,
        #                          validation_data=[X_valid, X_valid])
        #
        # def show_reconstructions(model, images=X_valid, n_images=5):
        #     reconstructions = model.predict(images[:n_images])
        #     fig = plt.figure(figsize=(n_images * 1.5, 3))
        #     for image_index in range(n_images):
        #         plt.subplot(2, n_images, 1 + image_index)
        #         plot_image(images[image_index])
        #         plt.subplot(2, n_images, 1 + n_images + image_index)
        #         plot_image(reconstructions[image_index])
        #
        # show_reconstructions(stacked_ae)
        # X_valid_compressed = stacked_encoder.predict(X_valid)
        # tsne = TSNE()
        # X_valid_2D = tsne.fit_transform(X_valid_compressed)
        # X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())
        # plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap="tab10")
        # plt.axis("off")
        # plt.show()
        #
        # plt.figure(figsize=(10, 8))
        # cmap = plt.cm.tab10
        # plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)
        # image_positions = np.array([[1., 1.]])
        # for index, position in enumerate(X_valid_2D):
        #     dist = np.sum((position - image_positions) ** 2, axis=1)
        #     if np.min(dist) > 0.02:  # if far enough from other images
        #         image_positions = np.r_[image_positions, [position]]
        #         imagebox = mpl.offsetbox.AnnotationBbox(
        #             mpl.offsetbox.OffsetImage(X_valid[index], cmap="binary"),
        #             position, bboxprops={"edgecolor": cmap(y_valid[index]), "lw": 2})
        #         plt.gca().add_artist(imagebox)
        # plt.axis("off")
        # plt.show()

        # unsupervised pretraining using stacked autoencoders
        # a complex supervised task, but we dont have enough training data, one solution is to
        # find a nn that performs a similar task and reuse its lower layers

        # tying weights
        # when an autoencoder is neatly symmetrical, like the one we just build
        # to tie the wights of the decoder layers to the weights of the encoder layers, it halves
        # the number of weights in the model.
        # class DenseTranspose(keras.layers.Layer):
        #     def __init__(self, dense, activation=None, **kwargs):
        #         self.dense = dense
        #         self.activation = keras.activations.get(activation)
        #         super().__init__(**kwargs)
        #
        #     def build(self, batch_input_shape):
        #         self.biases = self.add_weight(name="bias",
        #                                       shape=[self.dense.input_shape[-1]],
        #                                       initializer="zeros")
        #         super().build(batch_input_shape)
        #
        #     def call(self, inputs):
        #         z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)
        #         return self.activation(z + self.biases)
        #
        # keras.backend.clear_session()
        # tf.random.set_seed(42)
        # np.random.seed(42)
        #
        # dense_1 = keras.layers.Dense(100, activation="selu")
        # dense_2 = keras.layers.Dense(30, activation="selu")
        #
        # tied_encoder = keras.models.Sequential([
        #     keras.layers.Flatten(input_shape=[28, 28]),
        #     dense_1,
        #     dense_2
        # ])
        #
        # tied_decoder = keras.models.Sequential([
        #     DenseTranspose(dense_2, activation="selu"),
        #     DenseTranspose(dense_1, activation="sigmoid"),
        #     keras.layers.Reshape([28, 28])
        # ])
        #
        # tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])
        #
        # tied_ae.compile(loss="binary_crossentropy",
        #                 optimizer=keras.optimizers.SGD(learning_rate=1.5), metrics=[rounded_accuracy])
        # history = tied_ae.fit(X_train, X_train, epochs=10,
        #                       validation_data=(X_valid, X_valid))

        # Convolutional AutoEncoders
        # if ure dealing with images, then the autoencoders we have seen so far will not work well
        # unless images are tiny,

        # def train_autoencoder(n_neurons, X_train, X_valid, loss, optimizer,
        #                       n_epochs=10, output_activation=None, metrics=None):
        #     n_inputs = X_train.shape[-1]
        #     encoder = keras.models.Sequential([
        #         keras.layers.Dense(n_neurons, activation="selu", input_shape=[n_inputs])
        #     ])
        #     decoder = keras.models.Sequential([
        #         keras.layers.Dense(n_inputs, activation=output_activation),
        #     ])
        #     autoencoder = keras.models.Sequential([encoder, decoder])
        #     autoencoder.compile(optimizer, loss, metrics=metrics)
        #     autoencoder.fit(X_train, X_train, epochs=n_epochs,
        #                     validation_data=(X_valid, X_valid))
        #     return encoder, decoder, encoder(X_train), encoder(X_valid)
        #
        # tf.random.set_seed(42)
        # np.random.seed(42)
        #
        # K = keras.backend
        # X_train_flat = K.batch_flatten(X_train)  # equivalent to .reshape(-1, 28 * 28)
        # X_valid_flat = K.batch_flatten(X_valid)
        # enc1, dec1, X_train_enc1, X_valid_enc1 = train_autoencoder(
        #     100, X_train_flat, X_valid_flat, "binary_crossentropy",
        #     keras.optimizers.SGD(learning_rate=1.5), output_activation="sigmoid",
        #     metrics=[rounded_accuracy])
        # enc2, dec2, _, _ = train_autoencoder(
        #     30, X_train_enc1, X_valid_enc1, "mse", keras.optimizers.SGD(learning_rate=0.05),
        #     output_activation="selu")
        # stacked_ae_1_by_1 = keras.models.Sequential([
        #     keras.layers.Flatten(input_shape=[28, 28]),
        #     enc1, enc2, dec2, dec1,
        #     keras.layers.Reshape([28, 28])
        # ])
        # show_reconstructions(stacked_ae_1_by_1)
        # plt.show()
        #
        # stacked_ae_1_by_1.compile(loss="binary_crossentropy",
        #                           optimizer=keras.optimizers.SGD(learning_rate=0.1), metrics=[rounded_accuracy])
        # history = stacked_ae_1_by_1.fit(X_train, X_train, epochs=10,
        #                                 validation_data=(X_valid, X_valid))

        # show_reconstructions(stacked_ae_1_by_1)
        # plt.show()

        # recurrent autoencoders
        # if you want to build an autoencoder for sequences, such as times series or text,
        # then rnn may be better suited than dense networks.
        # building recurrent autoencoder is straightforward.
        # the encoder is s-to-v rnn, compresses the input down to a single vector.
        # decoder is v-to-s rnn does reverse
        #
        # recurrent_encoder = keras.models.Sequential([
        #     keras.layers.LSTM(100, return_sequences=True, input_shape=[28, 28]),
        #     keras.layers.LSTM(30)
        # ])
        # recurrent_decoder = keras.models.Sequential([
        #     keras.layers.RepeatVector(28, input_shape=[30]),
        #     keras.layers.LSTM(100, return_sequences=True),
        #     keras.layers.TimeDistributed(keras.layers.Dense(28, activation="sigmoid"))
        # ])
        # recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])
        # recurrent_ae.compile(loss="binary_crossentropy", optimizer=keras.optimizers.SGD(0.1),
        #                      metrics=[rounded_accuracy])
        # history = recurrent_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))
        # show_reconstructions(recurrent_ae)
        # plt.show()

        # denoising autoencoderes
        # to force to learn useful features is to add noise to its inputs
        # and recovering original
        # tf.random.set_seed(42)
        # np.random.seed(42)
        #
        # denoising_encoder = keras.models.Sequential([
        #     keras.layers.Flatten(input_shape=[28, 28]),
        #     keras.layers.GaussianNoise(0.2),
        #     keras.layers.Dense(100, activation="selu"),
        #     keras.layers.Dense(30, activation="selu")
        # ])
        # denoising_decoder = keras.models.Sequential([
        #     keras.layers.Dense(100, activation="selu", input_shape=[30]),
        #     keras.layers.Dense(28 * 28, activation="sigmoid"),
        #     keras.layers.Reshape([28, 28])
        # ])
        # denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])
        # denoising_ae.compile(loss="binary_crossentropy", optimizer=keras.optimizers.SGD(learning_rate=1.0),
        #                      metrics=[rounded_accuracy])
        # history = denoising_ae.fit(X_train, X_train, epochs=10,
        #                            validation_data=(X_valid, X_valid))

        # noise = keras.layers.GaussianNoise(0.2)
        # show_reconstructions(denoising_ae, noise(X_valid, training=True))
        # plt.show()

        # sparse autoencoder
        # by adding an approptiate term to the cost function
        # the autoencoder is pushed to reduce the number of active neuron in the coding layer.
        # simple_encoder = keras.models.Sequential([
        #     keras.layers.Flatten(input_shape=[28, 28]),
        #     keras.layers.Dense(100, activation="selu"),
        #     keras.layers.Dense(30, activation="sigmoid"),
        # ])
        # simple_decoder = keras.models.Sequential([
        #     keras.layers.Dense(100, activation="selu", input_shape=[30]),
        #     keras.layers.Dense(28 * 28, activation="sigmoid"),
        #     keras.layers.Reshape([28, 28])
        # ])
        # simple_ae = keras.models.Sequential([simple_encoder, simple_decoder])
        # simple_ae.compile(loss="binary_crossentropy", optimizer=keras.optimizers.SGD(learning_rate=1.),
        #                   metrics=[rounded_accuracy])
        # history = simple_ae.fit(X_train, X_train, epochs=10,
        #                         validation_data=(X_valid, X_valid))
        # show_reconstructions(simple_ae)
        # plt.show()

        # Variational Autoencoders
        # it is introduces and became so popular
        # they are probabilistic autoencoders, chance partly determines their outputs.
        # Even after training
        # they are generative autoencoders, they can generate new instances by themselves
        #

        # class Sampling(keras.layers.Layer):
        #     def call(self, inputs):
        #         mean, log_var = inputs
        #         return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean
        #
        # tf.random.set_seed(42)
        # np.random.seed(42)
        #
        # codings_size = 10
        #
        # inputs = keras.layers.Input(shape=[28, 28])
        # z = keras.layers.Flatten()(inputs)
        # z = keras.layers.Dense(150, activation="selu")(z)
        # z = keras.layers.Dense(100, activation="selu")(z)
        # codings_mean = keras.layers.Dense(codings_size)(z)
        # codings_log_var = keras.layers.Dense(codings_size)(z)
        # codings = Sampling()([codings_mean, codings_log_var])
        # variational_encoder = keras.models.Model(
        #     inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])
        #
        # decoder_inputs = keras.layers.Input(shape=[codings_size])
        # x = keras.layers.Dense(100, activation="selu")(decoder_inputs)
        # x = keras.layers.Dense(150, activation="selu")(x)
        # x = keras.layers.Dense(28 * 28, activation="sigmoid")(x)
        # outputs = keras.layers.Reshape([28, 28])(x)
        # variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])
        #
        # _, _, codings = variational_encoder(inputs)
        # reconstructions = variational_decoder(codings)
        # variational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])
        #
        # latent_loss = -0.5 * K.sum(
        #     1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),
        #     axis=-1)
        # variational_ae.add_loss(K.mean(latent_loss) / 784.)
        # variational_ae.compile(loss="binary_crossentropy", optimizer="rmsprop", metrics=[rounded_accuracy])
        # history = variational_ae.fit(X_train, X_train, epochs=25, batch_size=128,
        #                              validation_data=(X_valid, X_valid))

        # Generative Adversarial Networks




def program1():
    TrainingExercises()


if __name__ == '__main__':
    program1()
